# Grocery Sales Analysis

![](images/Screenshot 2025-02-02 133638.png)

This notebook is a straightforward R analysis of a grocery sales dataset leftover from my MS Data Analytics program's first semester. This was originally a MySQL turned BigQuery project. Now, it's a Kaggle R notebook showing off lots of joins with the seven database tables. So, this code is essentially SQL queries converted into R joins. Enjoy!

## Overview

The Grocery Sales Database is a structured relational dataset designed for analyzing sales transactions, customer demographics, product details, employee records, and geographical information across multiple cities and countries. From the lived experience of wrangling these files, there are some insights to be gained, but they are shallow due to the limited four month time scope of the data. It is not possible to do any kind of seasonality analysis or forecasting from this dataset. Primarily, it's good practice for beginners in data management. The data types listed below are all SQL data types; adapt them to R as needed.

## Database Schema

The dataset consists of seven interconnected tables:

| File Name | Description |
|------------------|------------------------------------------------------|
| `categories.csv` | Defines the categories of the products. |
| `cities.csv` | Contains city-level geographic data. |
| `countries.csv` | Stores country-related metadata. |
| `customers.csv` | Contains information about the customers who make purchases. |
| `employees.csv` | Stores details of employees handling sales transactions. |
| `products.csv` | Stores details about the products being sold. |
| `sales.csv` | Contains transactional data for each sale. |

## Table Descriptions

### 1. categories

| Key | Column Name | Data Type | Description |
|-------------|-------------|-------------|----------------------------------|
| PK | `CategoryID` | `INT` | Unique identifier for each product category. |
|  | `CategoryName` | `VARCHAR(45)` | Name of the product category. |

### 2. cities

| Key | Column Name | Data Type      | Description                             |
|-----|-------------|----------------|-----------------------------------------|
| PK  | `CityID`    | `INT`          | Unique identifier for each city.        |
|     | `CityName`  | `VARCHAR(45)`  | Name of the city.                       |
|     | `Zipcode`   | `DECIMAL(5,0)` | Population of the city.                 |
| FK  | `CountryID` | `INT`          | Reference to the corresponding country. |

### 3. countries

| Key | Column Name   | Data Type     | Description                         |
|-----|---------------|---------------|-------------------------------------|
| PK  | `CountryID`   | `INT`         | Unique identifier for each country. |
|     | `CountryName` | `VARCHAR(45)` | Name of the country.                |
|     | `CountryCode` | `VARCHAR(2)`  | Two-letter country code.            |

### 4. customers

| Key | Column Name     | Data Type     | Description                          |
|-----|-----------------|---------------|--------------------------------------|
| PK  | `CustomerID`    | `INT`         | Unique identifier for each customer. |
|     | `FirstName`     | `VARCHAR(45)` | First name of the customer.          |
|     | `MiddleInitial` | `VARCHAR(1)`  | Middle initial of the customer.      |
|     | `LastName`      | `VARCHAR(45)` | Last name of the customer.           |
| FK  | `cityID`        | `INT`         | City of the customer.                |
|     | `Address`       | `VARCHAR(90)` | Residential address of the customer. |

### 5. employees

| Key | Column Name     | Data Type     | Description                          |
|-----|-----------------|---------------|--------------------------------------|
| PK  | `EmployeeID`    | `INT`         | Unique identifier for each employee. |
|     | `FirstName`     | `VARCHAR(45)` | First name of the employee.          |
|     | `MiddleInitial` | `VARCHAR(1)`  | Middle initial of the employee.      |
|     | `LastName`      | `VARCHAR(45)` | Last name of the employee.           |
|     | `BirthDate`     | `DATE`        | Date of birth of the employee.       |
|     | `Gender`        | `VARCHAR(10)` | Gender of the employee.              |
| FK  | `CityID`        | `INT`         | unique identifier for city           |
|     | `HireDate`      | `DATE`        | Date when the employee was hired.    |

### 6. products

| Key | Column Name    | Data Type      | Description                               |
|-------------|---------------------------|-------------|--------------------|
| PK  | `ProductID`    | `INT`          | Unique identifier for each product.       |
|     | `ProductName`  | `VARCHAR(45)`  | Name of the product.                      |
|     | `Price`        | `DECIMAL(4,0)` | Price per unit of the product.            |
|     | `CategoryID`   | `INT`          | unique category identifier                |
|     | `Class`        | `VARCHAR(15)`  | Classification of the product.            |
|     | `ModifyDate`   | `DATE`         | Last modified date.                       |
|     | `Resistant`    | `VARCHAR(15)`  | Product resistance category.              |
|     | `IsAllergic`   | `VARCHAR`      | indicates whether the item is an allergen |
|     | `VitalityDays` | `DECIMAL(3,0)` | Product vital type classification.        |

### 7. sales

| Key | Column Name | Data Type | Description |
|-------------|---------------------|-------------|--------------------------|
| PK | `SalesID` | `INT` | Unique identifier for each sale. |
| FK | `SalesPersonID` | `INT` | Employee responsible for the sale. |
| FK | `CustomerID` | `INT` | Customer making the purchase. |
| FK | `ProductID` | `INT` | Product being sold. |
|  | `Quantity` | `INT` | Number of units sold. |
|  | `Discount` | `DECIMAL(10,2)` | Discount applied to the sale. |
|  | `TotalPrice` | `DECIMAL(10,2)` | Final sale price after discounts. |
|  | `SalesDate` | `DATETIME` | Date and time of the sale. |
|  | `TransactionNumber` | `VARCHAR(25)` | Unique identifier for the transaction. |

## Use Cases

Despite being a four-month snapshot and existing independently of external data sources, this dataset offers a rich environment for aspiring data scientists to practice and enhance their SQL skills. Here are some approachable and practical use cases:

### 1. **Monthly Sales Performance**

-   **Objective:** Analyze sales performance within the four-month period to identify trends and patterns.
-   **Tasks:**
    -   Calculate total sales for each month.
    -   Compare sales performance across different product categories each month.

### 2. **Top Products Identification**

-   **Objective:** Determine which products are the best and worst performers within the dataset timeframe.
-   **Tasks:**
    -   Rank products based on total sales revenue.
    -   Analyze sales quantity and revenue to identify high-demand products.
    -   Examine the impact of product classifications on sales performance.

### 3. **Customer Purchase Behavior**

-   **Objective:** Understand how customers interact with products during the four-month period.
-   **Tasks:**
    -   Segment customers based on their purchase frequency and total spend.
    -   Identify repeat customers versus one-time buyers.
    -   Analyze average order value and basket size.

### 4. **Salesperson Effectiveness**

-   **Objective:** Evaluate the performance of sales personnel in driving sales.
-   **Tasks:**
    -   Calculate total sales attributed to each salesperson.
    -   Identify top-performing and underperforming sales staff.
    -   Analyze sales trends based on individual salesperson contributions over time.

### 5. **Geographical Sales Insights**

-   **Objective:** Explore how sales are distributed across different cities and countries within the dataset.
-   **Tasks:**
    -   Map sales data to specific cities and countries to identify high-performing regions.
    -   Compare sales volumes between various geographical areas.
    -   Assess the effectiveness of regional sales strategies.

**Database Schema**: ![](https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F8067701%2Fd49f2fdeb62fe52ff5cb5bfc5f7f217c%2FScreenshot%202025-01-31%20123107.png?generation=1738348489608387&alt=media)

## Data Relationships

-   **Sales:** Each sale is linked to a **Product**, **Customer**, and **Employee** through their respective IDs. Each sale is linked to a location via the customer.
-   **Customers:** Associated with a **City** and a **Country** to provide geographic context.
-   **Employees:** Manage sales and are uniquely identified by **EmployeeID**.
-   **Products:** Categorized under specific **Categories** to organize the inventory.
-   **Geography:** **Cities** belong to **Countries**, offering higher-level geographic segmentation.

```{r}
if (!requireNamespace("Hmisc", quietly = TRUE)) {
  install.packages("Metrics")
}
if (!requireNamespace("naniar", quietly = TRUE)) {
  install.packages("Metrics")
}

library(tidyverse)
library(Hmisc)
library(naniar)

# Import each CSV file as a dataframe with the path prefix
categories <- read.csv("categories.csv")
cities <- read.csv("cities.csv")
countries <- read.csv("countries.csv")
customers <- read.csv("customers.csv")
employees <- read.csv("employees.csv")
products <- read.csv("products.csv")
sales <- read.csv("sales.csv")

str(categories)
str(cities)
str(countries)
str(customers)
str(employees)
str(products)
str(sales)
```

## Unique Countries

The code is designed to extract distinct records identifying countries from the `cities` table and join them with the `CountryName` from the `countries` table. The use of `INNER JOIN` ensures that only matching records, where `CountryID` corresponds in both `cities` and `countries` tables, are returned.

From the query result, we observe that although the `countries` table contains 206 distinct entries, indicating a broad international dataset, the actual outcome reveals a narrower scope. The result set includes only one country, the United States, suggesting that the cities within the `cities` table are exclusively from this country. This limits the geographical breadth of any analysis to the United States.

In summary, while the `countries` table suggests a dataset with global coverage, the actual data from the `cities` table is geographically constrained to the United States. This significantly narrows the analytical scope to U.S. cities only, shaping any subsequent data exploration or business insights to be region-specific.

```{r}
# Perform the join and select distinct countries
distinct_countries <- cities %>%
  inner_join(countries, by = "CountryID") %>%
  distinct(CountryID, CountryName)

# View the result
print(distinct_countries)
```
## Price Summary Analysis

The following R code snippet is designed to calculate key summary statistics for product prices from a sales dataset. Specifically, it computes the minimum, maximum, and median values of the `TotalPrice` column. By leveraging the `dplyr` package, the code efficiently processes the data to provide these insights. The `min` and `max` functions are used to determine the lowest and highest prices, respectively, while the `quantile` function is employed to find the median price, offering a central tendency measure. This analysis is crucial for understanding the price distribution within the dataset, enabling more informed decision-making and strategic planning.

```{r}
# Calculate min, max, and median price
price_summary <- products %>%
  summarise(
    min_price = min(Price),
    max_price = max(Price),
    median_price = quantile(Price, 0.5)
  )

# View the result
print(price_summary)
```

## Min/Max `SalesDate`

Simply using Kaggle's data explorer, we find the order dates range from `2017-12-31` to `2018-05-09`.

```{r}
# Calculate min and max sales dates
min_sales_date <- min(sales$SalesDate)
max_sales_date <- max(sales$SalesDate)

# View the result
print(min_sales_date)
print(max_sales_date)
```

From this output, we can conclude that the dataset encompasses a little over four months of sales data, limiting any analysis to the first quarter (Q1) and part of the second quarter (Q2) of 2018. Due to this limited timeframe, it would indeed be insufficient to conduct analyses that require a longer temporal scope, such as seasonality trends, year-over-year growth, or quarter-over-quarter comparisons. Such analyses typically require at least one full year of data to account for seasonal variations and other temporal trends that could influence sales data. The restricted time span in this dataset precludes those kinds of temporal analyses and indicates that any conclusions drawn would be constrained to the early part of 2018 only.

## Price Summary Analysis

```{r}
# Calculate min, max, and median total price
price_summary <- sales %>%
  summarise(
    min_price = min(TotalPrice, na.rm = TRUE),
    max_price = max(TotalPrice, na.rm = TRUE),
    median_price = median(TotalPrice, na.rm = TRUE)
  )

# View the result
print(price_summary)
```
