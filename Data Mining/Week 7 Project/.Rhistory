?strptime
install.packages(naniar)
install.packages("naniar")
install.packages("naniar")
# Load packages
library(palmerpenguins) # data source
library(tidyverse)
library(dplyr)
library(naniar)
install.packages('naniar')
library(naniar)
install.packages("naniar")
install.packages('Rtools')
install.packages('naniar')
install.packages("naniar")
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
detach("package:stats", unload = TRUE)
detach("package:utils", unload = TRUE)
library(utils, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:methods", unload = TRUE)
detach("package:graphics", unload = TRUE)
detach("package:grDevices", unload = TRUE)
detach("package:datasets", unload = TRUE)
install.packages("naniar")
dbinom(5, 10, 0.5)
dbinom(6, 10, 0.5)
dbinom(10, 10, 0.5)
p_value <- 1 - pnorm(2.15, mean = 127, sd = 39, lower.tail = FALSE)
p_value
# Define the t-value and degrees of freedom
t_value <- 3
df <- 2
# Find the cumulative probability up to the positive t-value
p_right_tail <- 1 - pt(t_value, df)
# Since the distribution is symmetric, the left tail area is the same as the right tail area
# Double the one tail area to get the total area outside plus/minus 3 units from the mean
total_tail_area <- 2 * p_right_tail
# Print the result
total_tail_area
t_value <- -1.79
df <- 19
p_right_tail <- 1-pt(t_value, df)
p_right_tail
0.069/sqrt(15)
2 * pt(1.47,99)
p_value <- 2 * (1 - pt(abs(1.47), 99))
p_value
# Values given in the problem
x_diff <- 12.76
SE_xdiff <- 1.67
df <- 72
# Calculating the t-score (already given in the problem as 7.65, but included here for completeness)
t_score <- (x_diff - 0) / SE_xdiff
# Calculating the p-value for a two-tailed test
p_value <- 2 * (1 - pt(abs(t_score), df))
# Output the t-score and p-value
print(paste("T-score:", t_score))
print(paste("P-value:", p_value))
install.packages("openintro")
install.packages("openintro")
install.packages("gss")
library(gss)
data(gss_all)
library(gss)
data(gss)
To generate a password meeting the specified requirements, we can break down the process into several steps:
# Define the password requirements
min_length <- 8
max_length <- 20
upper_case <- LETTERS
lower_case <- letters
numbers <- 0:9
special_chars <- c("!", "@", "$", "*", "+", "-")
max_repeating_chars <- 2
max_consecutive_numbers <- 8
email <- "example@example.com"
# Function to generate a random password
generate_password <- function() {
# Generate a random length between min_length and max_length
length <- sample(min_length:max_length, 1)
# Generate a random password string
password <- paste0(sample(c(upper_case, lower_case, numbers, special_chars), length, replace = TRUE), collapse = "")
return(password)
}
# Function to check if a password meets the requirements
check_requirements <- function(password) {
# Check length requirement
if (nchar(password) < min_length | nchar(password) > max_length) {
return(FALSE)
}
# Check if it contains upper case letters
if (!any(grepl("[A-Z]", password))) {
return(FALSE)
}
# Check if it contains lower case letters
if (!any(grepl("[a-z]", password))) {
return(FALSE)
}
# Check if it contains at least one number
if (!any(grepl("[0-9]", password))) {
return(FALSE)
}
# Check if it contains at least one special character
if (!any(grepl("[!@\\$*+\\-]", password))) {
return(FALSE)
}
# Check for repeating characters
if (any(gregexpr("(.)\\1{2,}", password)[[1]] != -1)) {
return(FALSE)
}
# Check for consecutive numbers
if (any(gregexpr("(0123456789){9,}", password)[[1]] != -1)) {
return(FALSE)
}
# Check if it contains the email address
if (grepl(email, password)) {
return(FALSE)
}
# If all requirements are met, return TRUE
return(TRUE)
}
# Generate and check password until all requirements are met
repeat {
password <- generate_password()
if (check_requirements(password)) {
break
}
}
# Output the final password
print(password)
setwd("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/Data Mining/Week 7 Project")
# Load packages
library(tidyverse)
# Load data
df <- read.csv("online_retail.csv")
str(df)
# Load packages
library(tidyverse)
# Load data
df <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
str(df)
# Remove cancellations: Filter out transactions that are cancellations (InvoiceNo starts with 'C')
df_clean <- df[!grepl("^C", df$InvoiceNo), ]
df_clean <- df_clean[df_clean$Quantity > 0, ]
# Aggregate items by InvoiceNo, removing duplicate items within each transaction
transactions <- df_clean %>%
group_by(InvoiceNo) %>%
summarise(Items = list(unique(Description)), .groups = 'drop')
head(transactions)
dim(df_clean)
df_clean <- df_clean[!is.na(df_clean$InvoiceNo), ]
df_clean <- df_clean[!is.na(df_clean$Description), ]
df_clean <- df_clean[!is.na(df_clean$StockCode), ]
dim(df_clean)
# Load packages
library(tidyverse)
# Load data
df <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
str(df)
# Remove cancellations: Filter out transactions that are cancellations (InvoiceNo starts with 'C')
df_clean <- df[!grepl("^C", df$InvoiceNo), ]
dim(df_clean)
df_clean <- df_clean[!is.na(df_clean$InvoiceNo), ]
df_clean <- df_clean[!is.na(df_clean$Description), ]
df_clean <- df_clean[!is.na(df_clean$StockCode), ]
dim(df_clean)
df_clean <- df_clean[df_clean$Quantity > 0, ]
# Aggregate items by InvoiceNo, removing duplicate items within each transaction
transactions <- df_clean %>%
group_by(InvoiceNo) %>%
summarise(Items = list(unique(Description)), .groups = 'drop')
head(transactions)
dim(df_clean)
# Aggregate items by InvoiceNo, removing duplicate items within each transaction
transactions <- df_clean %>%
group_by(InvoiceNo) %>%
summarise(Items = list(unique(Description)), .groups = 'drop')
dim(transactions)
head(transactions, 10)
# Aggregate items by InvoiceNo, removing duplicate items within each transaction
transactions <- df_clean %>%
group_by(InvoiceNo) %>%
summarise(Items = toString(unique(Description)), .groups = 'drop')
head(transactions, 10)
install.packages("arules")
# Load packages
library(tidyverse)
library(arules)
# Load data
df <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
str(df)
# Remove cancellations: Filter out transactions that are cancellations (InvoiceNo starts with 'C')
df_clean <- df[!grepl("^C", df$InvoiceNo), ]
dim(df_clean)
df_clean <- df_clean[!is.na(df_clean$InvoiceNo), ]
df_clean <- df_clean[!is.na(df_clean$Description), ]
df_clean <- df_clean[!is.na(df_clean$StockCode), ]
dim(df_clean)
df_clean <- df_clean[df_clean$Quantity > 0, ]
dim(df_clean)
# Aggregate items by InvoiceNo, removing duplicate items within each transaction
transactions <- df_clean %>%
group_by(InvoiceNo) %>%
summarise(Items = toString(unique(Description)), .groups = 'drop')
head(transactions, 10)
# Transform InvoiceNo to factor
df_clean$InvoiceNo = factor(df_clean$InvoiceNo)
# Split into groups
data_list = split(df_clean$StockCode, df_clean$InvoiceNo)
# Transform to transactional dataset
data_trx = as(data_list,"transactions")
# Inspect transactions
inspect(head(data_trx))
# Transform InvoiceNo to factor
df_clean$InvoiceNo = factor(df_clean$InvoiceNo)
# Split into groups
data_list = split(df_clean$StockCode, df_clean$InvoiceNo)
# Transform to transactional dataset
data_trx = as(data_list,"transactions")
# Inspect transactions
inspect(head(data_trx))
summary(data_trx)
# Load packages
library(tidyverse)
library(arules)
# Load data
df <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
str(df)
# Remove cancellations: Filter out transactions that are cancellations (InvoiceNo starts with 'C')
df_clean <- df[!grepl("^C", df$InvoiceNo), ]
dim(df_clean)
df_clean <- df_clean[!is.na(df_clean$InvoiceNo), ]
df_clean <- df_clean[!is.na(df_clean$Description), ]
df_clean <- df_clean[!is.na(df_clean$StockCode), ]
dim(df_clean)
df_clean <- df_clean[df_clean$Quantity > 0, ]
dim(df_clean)
# Transform InvoiceNo to factor
df_clean$InvoiceNo = factor(df_clean$InvoiceNo)
# Split into groups
data_list = split(df_clean$Description, df_clean$InvoiceNo)
# Transform to transactional dataset
data_trx = as(data_list,"transactions")
# Inspect transactions
inspect(head(data_trx))
summary(data_trx)
image(data_trx)
image(data_trx[1:500,])
frequent_itemsets = apriori(df_clean,
parameter=list(
# Minimum support
supp=0.2,
# Minimum confidence
conf = 0.4,
# Minimum length
minlen = 2,
# Target
target="frequent itemsets"))
inspect(head(sort(frequent_itemsets,by="support"),3))
frequent_itemsets = apriori(df_clean,
parameter=list(
# Minimum support
supp=0.2,
# Minimum confidence
conf = 0.4,
# Minimum length
minlen = 2,
# Target
target="frequent itemsets"))
inspect(head(sort(frequent_itemsets,by="support"),10))
# Load packages
library(tidyverse)
library(arules)
# Read and preprocess data
data <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
data <- data[!grepl("^C", data$InvoiceNo), ]  # Remove cancellations
data <- data[!is.na(data$Description), ]  # Remove missing descriptions
data <- data[data$Quantity > 0, ]  # Only positive quantities
# Aggregate items into transactions
transactions <- data %>%
group_by(InvoiceNo) %>%
summarise(Items = paste(unique(Description), collapse = ",")) %>%
ungroup()
# Convert to transactions class
trans_list <- strsplit(as.character(transactions$Items), ",")
trans <- as(trans_list, "transactions")
# Run apriori algorithm
frequent_itemsets <- apriori(trans,
parameter = list(supp = 0.01,  # Adjusted support threshold
conf = 0.1,   # Adjusted confidence threshold
target = "frequent itemsets"))
# Inspect the frequent itemsets
inspect(head(sort(frequent_itemsets, by="support"), 10))
# Load packages
library(tidyverse)
library(arules)
# Read and preprocess data
data <- read.csv("online_retail.csv", stringsAsFactors = FALSE)
data <- data[!grepl("^C", data$InvoiceNo), ]  # Remove cancellations
data <- data[!is.na(data$Description), ]  # Remove missing descriptions
data <- data[data$Quantity > 0, ]  # Only positive quantities
# Aggregate items into transactions
transactions <- data %>%
group_by(InvoiceNo) %>%
summarise(Items = paste(unique(Description), collapse = ",")) %>%
ungroup()
# Convert to transactions class
trans_list <- strsplit(as.character(transactions$Items), ",")
trans <- as(trans_list, "transactions")
# Run apriori algorithm
frequent_itemsets <- apriori(trans,
parameter = list(supp = 0.05,  # Adjusted support threshold
conf = 0.1,   # Adjusted confidence threshold
target = "frequent itemsets"))
# Inspect the frequent itemsets
inspect(head(sort(frequent_itemsets, by="support"), 10))
# Calculate association rules using the apriori algorithm
rules <- apriori(trans,
parameter = list(supp = 0.025,  # Support threshold
conf = 0.1),  # Confidence threshold
appearance = NULL,
control = NULL,
target = "rules")
# Inspect the top 10 association rules sorted by confidence
inspect(head(sort(rules, by="confidence"), 10))
install.packages("arulesViz")
library(arulesViz)
inspectDT(rules)
library(plotly)
library(plotly)
plot(rules, engine = "plotly")
library(plotly)
plot(rules, engine = "plotly", xlim = c(0.2, 0.5))
plot(rules)
plot(rules, jitter=2)
plot(rules, method = "scatterplot", measure = "support", shading = "lift", jitter = 2, xlim = c(0.2, 0.45))
# Filter rules by support
filtered_rules <- subset(rules, subset = support >= 0.2 & support <= 0.45)
# Plot the filtered rules
plot(filtered_rules, method = "scatterplot", measure = "support", shading = "lift", jitter = 2)
# Plot the filtered rules
plot(filtered_rules, method = "scatterplot", measure = "support", shading = "lift", jitter = 2)
# Plot the filtered rules
plot(filtered_rules, method = "scatterplot", measure = "support", shading = "lift", jitter = 2)
# Plot the filtered rules
plot(rules, method = "scatterplot", measure = "support", shading = "lift", jitter = 2)
# Plot the filtered rules
plot(rules, jitter = 2)
# Plot the filtered rules
plot(rules, jitter = 2, method="matrix3D")
# Plot the filtered rules
plot(rules, jitter = 2)
# This visualization is INTERACTIVE. Please explore!
library(plotly)
plot(rules, engine = "plotly", )
source("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/Data Mining/Week 7 Project/DATA5150_Week7_Project3_Market-Basket-Analysis-Using-Apriori-Algorithm.Rmd")
# This visualization is INTERACTIVE. Please explore!
library(plotly)
plot(rules, engine = "plotly")
