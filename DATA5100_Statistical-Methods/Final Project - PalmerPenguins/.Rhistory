?strptime
install.packages(naniar)
install.packages("naniar")
install.packages("naniar")
# Load packages
library(palmerpenguins) # data source
library(tidyverse)
library(dplyr)
library(naniar)
install.packages('naniar')
library(naniar)
install.packages("naniar")
install.packages('Rtools')
install.packages('naniar')
install.packages("naniar")
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
install.packages(c("BH", "bslib", "cli", "cpp11", "crosstalk", "curl", "data.table", "DBI", "dbplyr", "digest", "dplyr", "evaluate", "fansi", "future", "future.apply", "ggplot2", "glue", "haven", "htmltools", "htmlwidgets", "jsonlite", "knitr", "later", "lifecycle", "lubridate", "markdown", "openssl", "plotly", "prettyunits", "processx", "progress", "ps", "ragg", "Rcpp", "RcppArmadillo", "readr", "recipes", "reprex", "rlang", "sass", "scales", "stringi", "stringr", "systemfonts", "textshaping", "tidyr", "timechange", "timeDate", "tinytex", "tseries", "TTR", "utf8", "uuid", "vctrs", "vroom", "withr", "xfun", "xml2", "xts", "yaml"))
detach("package:stats", unload = TRUE)
detach("package:utils", unload = TRUE)
library(utils, lib.loc = "C:/Program Files/R/R-4.3.1/library")
detach("package:methods", unload = TRUE)
detach("package:graphics", unload = TRUE)
detach("package:grDevices", unload = TRUE)
detach("package:datasets", unload = TRUE)
install.packages("naniar")
dbinom(5, 10, 0.5)
dbinom(6, 10, 0.5)
dbinom(10, 10, 0.5)
p_value <- 1 - pnorm(2.15, mean = 127, sd = 39, lower.tail = FALSE)
p_value
# Define the t-value and degrees of freedom
t_value <- 3
df <- 2
# Find the cumulative probability up to the positive t-value
p_right_tail <- 1 - pt(t_value, df)
# Since the distribution is symmetric, the left tail area is the same as the right tail area
# Double the one tail area to get the total area outside plus/minus 3 units from the mean
total_tail_area <- 2 * p_right_tail
# Print the result
total_tail_area
t_value <- -1.79
df <- 19
p_right_tail <- 1-pt(t_value, df)
p_right_tail
0.069/sqrt(15)
2 * pt(1.47,99)
p_value <- 2 * (1 - pt(abs(1.47), 99))
p_value
# Values given in the problem
x_diff <- 12.76
SE_xdiff <- 1.67
df <- 72
# Calculating the t-score (already given in the problem as 7.65, but included here for completeness)
t_score <- (x_diff - 0) / SE_xdiff
# Calculating the p-value for a two-tailed test
p_value <- 2 * (1 - pt(abs(t_score), df))
# Output the t-score and p-value
print(paste("T-score:", t_score))
print(paste("P-value:", p_value))
install.packages("openintro")
install.packages("openintro")
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
}
# Calculating the Z-score for part (c)
z_score_c <- calculate_z_score(p_population, p_sample, n)
# Output the Z-score
print(paste("The Z-score for part (c) is:", z_score_c))
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
}
# Calculating the Z-score for part (c)
z_score_c <- round(calculate_z_score(p_population, p_sample, n), 2)
# Output the Z-score
print(paste("The Z-score for part (c) is:", z_score_c))
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
}
# Calculating the Z-score for part (c)
z_score_c <- round(calculate_z_score(p_population, p_sample, n), 2)
# Output the Z-score
print(paste("The calculated standard error is:", se))
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
}
# Calculating the Z-score for part (c)
z_score_c <- round(calculate_z_score(p_population, p_sample, n), 2)
# Output the Z-score
print(paste("The calculated standard error is:", se))
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
return(se)
}
# Calculating the Z-score for part (c)
z_score_c <- round(calculate_z_score(p_population, p_sample, n), 2)
# Output the Z-score
print(paste("The calculated standard error is:", se))
# Given values
p_population <- 0.08  # Population proportion
p_sample <- 0.12      # Sample proportion
n <- 125              # Sample size
# Function to calculate standard error
calculate_se <- function(p, n) {
sqrt(p * (1 - p) / n)
return(se)
}
# Function to calculate Z-score
calculate_z_score <- function(p_population, p_sample, n) {
se <- calculate_se(p_population, n)
z_score <- (p_sample - p_population) / se
return(z_score)
}
# Calculating the Z-score for part (c)
z_score_c <- round(calculate_z_score(p_population, p_sample, n), 2)
# Given values
p_population <- 0.08  # population proportion
p_sample_c <- 0.12    # sample proportion for part (c)
n_c <- 125            # sample size for part (c)
# Standard error calculation
se_c <- sqrt(p_population * (1 - p_population) / n_c)
# Z-score calculation for part (c)
z_c <- (p_sample_c - p_population) / se_c
# Print the results
cat("The standard error for part (c) is:", se_c, "\n")
cat("The z-score for part (c) is:", z_c)
# Given values
p_population <- 0.08  # population proportion
p_sample_c <- 0.12    # sample proportion for part (c)
n_c <- 125            # sample size for part (c)
# Standard error calculation
se_c <- round(sqrt(p_population * (1 - p_population) / n_c), 4)
# Z-score calculation for part (c)
z_c <- round(((p_sample_c - p_population) / se_c), 2)
# Print the results
cat("The standard error for part (c) is:", se_c, "\n")
cat("The z-score for part (c) is:", z_c)
# Given values
p_population <- 0.08  # population proportion
p_sample_c <- 0.12    # sample proportion for part (c)
n_c <- 125            # sample size for part (c)
# Standard error calculation
se_c <- sqrt(p_population * (1 - p_population) / n_c)
# Z-score calculation for part (c)
z_c <- (p_sample_c - p_population) / se_c
# Print the results
cat("The standard error for part (c) is:", se_c, "\n")
cat("The z-score for part (c) is:", z_c)
p_population <- 0.08  # population proportion
p_sample_c <- 0.12    # sample proportion for part (c)
n_c <- 125            # sample size for part (c)
# Standard error calculation
se_c <- round(sqrt(p_population * (1 - p_population) / n_c), 4)
# Z-score calculation for part (c)
z_c <- round(((p_sample_c - p_population) / se_c), 2)
# Print the results
cat("The standard error for part (c) is:", se_c, "\n")
cat("The z-score for part (c) is:", z_c)
# Given values
p_population <- 0.08  # population proportion
p_sample_d <- 0.12    # sample proportion for part (d)
n_d <- 250            # sample size for part (d)
# Standard error calculation
se_d <- round(sqrt(p_population * (1 - p_population) / n_d), 4)
# Z-score calculation for part (d)
z_d <- round(((p_sample_d - p_population) / se_d), 2)
# Print the results
cat("The standard error for part (d) is:", se_d, "\n")
cat("The z-score for part (d) is:", z_d)
# Given values
p_population <- 0.08  # population proportion
n_small <- 125        # smaller sample size
n_large <- 250        # larger sample size
# Standard error calculations for both sample sizes
se_small <- sqrt(p_population * (1 - p_population) / n_small)
se_large <- sqrt(p_population * (1 - p_population) / n_large)
# Calculate the ratio of the standard errors
se_ratio <- se_small / se_large
# Print the results
cat("The standard error for the sample size of 125 is:", se_small, "\n")
cat("The standard error for the sample size of 250 is:", se_large, "\n")
cat("The ratio of the standard errors (125 to 250) is:", se_ratio, "\n")
# Check if the ratio is 0.5
if (se_ratio == 0.5) {
cat("Statement (e) is true: Doubling the sample size reduces the standard error by half.\n")
} else {
cat("Statement (e) is false: Doubling the sample size does not reduce the standard error by half.\n")
}
# Given values
p_hat <- 0.56  # Sample proportion
n <- 600       # Sample size
z <- 1.96      # Z-score for 95% confidence
# Calculate the margin of error
margin_of_error <- z * sqrt((p_hat * (1 - p_hat)) / n)
# Print the result
cat("The margin of error for the 56% point estimate is:", margin_of_error)
# Given values
p_hat <- 0.56  # Sample proportion
n <- 600       # Sample size
z <- 1.96      # Z-score for 95% confidence
# Calculate the margin of error
margin_of_error <- round((z * sqrt((p_hat * (1 - p_hat)) / n)), 4)
# Print the result
cat("The margin of error for the 56% point estimate is:", margin_of_error)
# Given values
successes <- 348
sample_size <- 400
p_hat <- successes / sample_size  # Sample proportion
# Standard error calculation
se <- sqrt(p_hat * (1 - p_hat) / sample_size)
# Z-score for 95% confidence interval
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- p_hat - z_score * se
upper_bound <- p_hat + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion is: [", lower_bound, ",", upper_bound, "]\n")
# Given values
successes <- 348
sample_size <- 400
p_hat <- successes / sample_size  # Sample proportion
# Standard error calculation
se <- sqrt(p_hat * (1 - p_hat) / sample_size)
# Z-score for 95% confidence interval
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- p_hat - z_score * se
upper_bound <- p_hat + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion is: [", lower_bound, ",", upper_bound, "]\n")
cat("Therefore, we are 95% confident that the true population proportion lies between", lower_bound, " and ", upper_bound)
# Given values
successes <- 348
sample_size <- 400
p_hat <- successes / sample_size  # Sample proportion
# Standard error calculation
se <- sqrt(p_hat * (1 - p_hat) / sample_size)
# Z-score for 95% confidence interval
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- p_hat - z_score * se
upper_bound <- p_hat + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion is: [", lower_bound, ",", upper_bound, "]\n")
cat("Therefore, we are 95% confident that the true population proportion of students who found a job within 1 year of completing their undergraduate degree lies between", lower_bound, " and ", upper_bound, ".")
# Given values
successes <- 348
sample_size <- 400
p_hat <- successes / sample_size  # Sample proportion
# Standard error calculation
se <- sqrt(p_hat * (1 - p_hat) / sample_size)
# Z-score for 99% confidence interval
z_score <- qnorm(0.995)  # Two-tailed
# Confidence interval calculation
lower_bound <- p_hat - z_score * se
upper_bound <- p_hat + z_score * se
# Print the confidence interval
cat("The 99% confidence interval for the proportion is: [", lower_bound, ",", upper_bound, "]\n")
cat("Therefore, we are 99% confident that the true population proportion of students who found a job within 1 year of completing their undergraduate degree lies between", lower_bound, " and ", upper_bound, ".")
# Given values
p_hat <- 0.55  # Sample proportion
n <- 1509      # Sample size
# Calculate the standard error
se <- sqrt(p_hat * (1 - p_hat) / n)
# Z-score for 90% confidence interval
z_score <- qnorm(0.95)  # One-tailed
# Confidence interval calculation
lower_bound <- p_hat - z_score * se
upper_bound <- p_hat + z_score * se
# Print the standard error and the confidence interval
cat("The standard error is:", se, "\n")
cat("The 90% confidence interval for the proportion is: [", lower_bound, ",", upper_bound, "]\n")
# Interpretation in context
cat("We are 90% confident that the true proportion of high school seniors who took the SAT",
"and are fairly certain they will participate in a study abroad program in college",
"is between", lower_bound, "and", upper_bound, ".\n")
# Given values
oppose <- 0.52  # Proportion of Independents that oppose the plan
n <- 783        # Sample size of Independents
# Calculate the standard error
se <- sqrt(oppose * (1 - oppose) / n)
# Z-score for 95% confidence interval (common choice for confidence level)
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- oppose - z_score * se
upper_bound <- oppose + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion of Independents who oppose the plan is: [", lower_bound, ",", upper_bound, "]\n")
# Check if the confidence interval includes 0.5
includes_50 <- (lower_bound <= 0.5) && (upper_bound >= 0.5)
cat("Does the confidence interval include 0.5? ", includes_50, "\n")
# Interpretation
if (includes_50) {
cat("We cannot be confident that a majority of Independents oppose the plan, as the confidence interval includes 0.5.\n")
} else {
cat("We can be confident that a majority of Independents oppose the plan, as the confidence interval does not include 0.5.\n")
}
# American data
p_hat_american <- 0.17 # Sample proportion of Americans
n_american <- 2254 # Sample size of Americans
p_chinese <- 0.38 # Comparison proportion of Chinese
# Standard error calculation for American data
se_american <- sqrt((p_hat_american * (1 - p_hat_american)) / n_american)
# Z-score calculation for the hypothesis test
z <- (p_hat_american - p_chinese) / se_american
# P-value calculation (two-tailed test)
p_value <- 2 * pnorm(z, lower.tail = FALSE)
# Print the results
cat("Z-score for the hypothesis test:", z, "\n")
cat("P-value for the hypothesis test:", p_value, "\n")
# American data
p_hat_american <- 0.17  # Sample proportion of Americans
n_american <- 2254      # Sample size of Americans
p_chinese <- 0.38       # Comparison proportion of Chinese
# Standard error calculation for American data
se_american <- sqrt((p_chinese * (1 - p_chinese)) / n_american) # Note: Use p_chinese for the SE under H0
# Z-score calculation for the hypothesis test
z <- (p_hat_american - p_chinese) / se_american
# P-value calculation (two-tailed test)
p_value <- 2 * pnorm(abs(z), lower.tail = FALSE)
# Print the results
cat("Z-score for the hypothesis test:", z, "\n")
cat("P-value for the hypothesis test:", p_value, "\n")
# Calculate the standard error
se <- sqrt((p_hat_american * (1 - p_hat_american)) / n_american)
# Z-score for 95% confidence interval
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- p_hat_american - z_score * se
upper_bound <- p_hat_american + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion of Americans who access the internet on their cell phones is: [", lower_bound, ",", upper_bound, "]\n")
# Interpretation in context
cat("We are 95% confident that the true proportion of Americans who access the internet on their cell phones lies between", lower_bound, "and", upper_bound, ".\n")
# Calculate the standard error
se <- sqrt((p_hat_american * (1 - p_hat_american)) / n_american)
# Z-score for 95% confidence interval
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
lower_bound <- round((p_hat_american - z_score * se), 4)
upper_bound <- round((p_hat_american + z_score * se), 4)
# Print the confidence interval
cat("The 95% confidence interval for the proportion of Americans who access the internet on their cell phones is: [", lower_bound, ",", upper_bound, "]\n")
# Interpretation in context
cat("We are 95% confident that the true proportion of Americans who access the internet on their cell phones lies between", lower_bound, "and", upper_bound, ".\n")
# Given values
n_correct <- 53  # Number of correct identifications
n_participants <- 80  # Total number of participants
p_random_guess <- 0.5  # Probability of a correct identification by random guessing
# Perform a binomial test
test_result <- binom.test(n_correct, n_participants, p_random_guess, alternative = "greater")
# Extract the p-value
p_value <- test_result$p.value
# Print the p-value
cat("The p-value for the hypothesis test is:", p_value, "\n")
# Interpretation
if (p_value < 0.05) {
cat("The p-value is less than 0.05, which suggests that there is strong evidence against the null hypothesis.",
"This means that the number of correct identifications is significantly higher than would be expected by random guessing.\n",
"Therefore, we can say that the data provide strong evidence that the participants are able to detect the difference between diet and regular soda.\n")
} else {
cat("The p-value is not less than 0.05, suggesting that there is not enough evidence to conclude that the participants can detect the difference",
"between diet and regular soda better than random guessing.\n")
}
# Given values
p_hat <- 40 / 200  # Sample proportion
n <- 200           # Sample size
# Standard error calculation
se <- sqrt(p_hat * (1 - p_hat) / n)
# Z-score for 95% confidence level
z_score <- qnorm(0.975)  # Two-tailed
# Confidence interval calculation
ci_lower <- p_hat - z_score * se
ci_upper <- p_hat + z_score * se
# Print the confidence interval
cat("The 95% confidence interval for the proportion of students who smoke is: [", ci_lower, ",", ci_upper, "]\n")
# Interpretation of the confidence interval
cat("We are 95% confident that the true proportion of students at the university who smoke is between", ci_lower, "and", ci_upper, ".\n")
# Desired margin of error
ME <- 0.02
# Sample size calculation
n_required <- (z_score * sqrt(p_hat * (1 - p_hat)) / ME)^2
# Print the required sample size
cat("The required sample size for a margin of error no larger than 2% is:", ceiling(n_required), "\n")
# Given values
p_hat <- 0.52  # Estimated proportion
margin_of_error <- 0.01  # Margin of error
confidence_level <- 0.90  # Confidence level
# Z-score for 90% confidence level
z_score <- qnorm(1 - (1 - confidence_level) / 2)
# Calculate required sample size
sample_size <- (z_score^2 * p_hat * (1 - p_hat)) / margin_of_error^2
sample_size <- ceiling(sample_size)  # Always round up
# Print the required sample size
cat("The required sample size for a 90% confidence interval with a margin of error of 1% is:", sample_size, "\n")
setwd("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/DATA5100_Statistical-Methods/Final Project - PalmerPenguins")
library(tidyverse)
#Read in Week 10 dataset
df <- readRDS("penguins_clean_w10.rds")
str(df)
unique(df$species)
table(df$species)
Adelie_weights_df <- filter(df, (species == 'Adelie')) %>%  select(weight)
Chinstrap_weights_df <- filter(df, (species == 'Chinstrap')) %>%  select(weight)
Gentoo_weights_df <- filter(df, (species == 'Gentoo')) %>%  select(weight)
Adelie_weights_df
Adelie_weights_df <- filter(df, (!is.na(), species == 'Adelie')) %>%  select(weight)
Adelie_weights_df <- filter(df, (!is.na(weight), species == 'Adelie')) %>%  select(weight)
Adelie_weights_df <- df %>%
filter(!is.na(weight), species == 'Adelie') %>%
select(weight)
Adelie_weights_df <- df %>%
filter(!is.na(weight),           # drop NA values
species == 'Adelie') %>%  # Adelie species
select(weight)
Adelie_weights <- Adelie_weights_df$weight
class(Adelie_weights)
??type
type(Adelie_weights)
??data type
Adelie_weights
