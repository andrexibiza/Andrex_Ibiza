n <- 100
sample_weights <- sample(df$weight, n, replace = TRUE) # Added replace = TRUE for sampling with replacement
#CONFIDENCE INTERVAL
#Construct 95% CI for weights based on sample
xbar <- mean(sample_weights, na.rm = TRUE) #sample mean
s <- sd(sample_weights, na.rm = TRUE) #sample sd
zc <- qnorm(0.975) # Corrected to only calculate once for the upper tail
se <- s/sqrt(n) # Changed to use sample standard deviation 's' instead of population 'sigma'
E <- zc*se
lower_bound_CI <- xbar - E
upper_bound_CI <- xbar + E
cat('95% confidence interval for population mean: (',lower_bound_CI,',',upper_bound_CI,')')
#TWO TAILED HYPOTHESIS TEST
#Step 1: HO: mu = mean(weights),  HA: mu != mean(weights)
claim <- "H0"
#Step 2:
alpha <- 0.05
zc <- qnorm(1 - alpha/2) # Corrected to find the critical value for both tails
#Step 3:
xbar <- mean(sample_weights, na.rm = TRUE)
mu_xbar = mu
se <- sigma/sqrt(n)
z = (xbar-mu_xbar)/se
if (!is.na(z)) { # Added check to ensure z is not NA before proceeding
if (z > 0) {
p <- (1- pnorm(z,0,1))*2
} else {
p <- pnorm(z,0,1)*2
}
z
p
#Step 4:
if (p > 0.05){
cat('Since p > 0.05: do not reject H0.')
rejectH0 <- FALSE
} else {
cat('Since p < 0.05: reject H0.')
rejectH0 <- TRUE
}
#Step 5
if (claim == "H0" & rejectH0 == TRUE){
cat('There is enough evidence to reject the claim.')
} else if (claim == "H0" & rejectH0 == FALSE) {
cat('There is not enough evidence to reject the claim.')
} else if (claim == "HA" & rejectH0 == TRUE) {
cat('There is enough evidence to support the claim.')
} else {
cat('There is not enough evidence to support the claim.')
}
}
#Confirm CI and hypothesis test with z.test function
z.test(sample_weights, mu = mu, sigma.x = sigma, conf.level = 0.95)
library(BSDA)
library(tidyverse)
library(dplyr)
# Read in Week 8 Dataset
df <- readRDS("penguins_clean_w8.rds")
#colnames(df)
library(BSDA)
#Find population mean and standard deviation
mu <- mean(df$weight, na.rm = TRUE) #population mean
sigma <- sd(df$weight, na.rm = TRUE) #population sd
cat('The population mean penguin weight is:',mu,'with population standard deviation',sigma)
#Take random sample of size greater than 30 with replacement.
n <- 100
sample_weights <- sample(df$weight, n, replace = TRUE) # Added replace = TRUE for sampling with replacement
#CONFIDENCE INTERVAL
#Construct 95% CI for weights based on sample
xbar <- mean(sample_weights, na.rm = TRUE) #sample mean
s <- sd(sample_weights, na.rm = TRUE) #sample sd
zc <- qnorm(0.975) # Corrected to only calculate once for the upper tail
se <- s/sqrt(n) # Changed to use sample standard deviation 's' instead of population 'sigma'
E <- zc*se
lower_bound_CI <- xbar - E
upper_bound_CI <- xbar + E
cat('95% confidence interval for population mean: (',lower_bound_CI,',',upper_bound_CI,')')
#TWO TAILED HYPOTHESIS TEST
#Step 1: HO: mu = mean(weights),  HA: mu != mean(weights)
claim <- "H0"
#Step 2:
alpha <- 0.05
zc <- qnorm(1 - alpha/2) # Corrected to find the critical value for both tails
#Step 3:
xbar <- mean(sample_weights, na.rm = TRUE)
mu_xbar = mu
se <- sigma/sqrt(n)
z = (xbar-mu_xbar)/se
if (!is.na(z)) { # Added check to ensure z is not NA before proceeding
if (z > 0) {
p <- (1- pnorm(z,0,1))*2
} else {
p <- pnorm(z,0,1)*2
}
z
p
#Step 4:
if (p > 0.05){
cat('Since p > 0.05: do not reject H0.')
rejectH0 <- FALSE
} else {
cat('Since p < 0.05: reject H0.')
rejectH0 <- TRUE
}
#Step 5
if (claim == "H0" & rejectH0 == TRUE){
cat('There is enough evidence to reject the claim.')
} else if (claim == "H0" & rejectH0 == FALSE) {
cat('There is not enough evidence to reject the claim.')
} else if (claim == "HA" & rejectH0 == TRUE) {
cat('There is enough evidence to support the claim.')
} else {
cat('There is not enough evidence to support the claim.')
}
}
#Confirm CI and hypothesis test with z.test function
z.test(sample_weights, mu = mu, sigma.x = sigma, conf.level = 0.95)
library(BSDA)
library(tidyverse)
library(dplyr)
#Find population mean and standard deviation
mu <- mean(df$weight, na.rm = TRUE) #population mean
sigma <- sd(df$weight, na.rm = TRUE) #population sd
cat('The population mean penguin weight is:',mu,'with population standard deviation',sigma)
#Take random sample of size greater than 30 with replacement.
n <- 100
sample_weights <- sample(df$weight, n, replace = TRUE) # Added replace = TRUE for sampling with replacement
#CONFIDENCE INTERVAL
#Construct 95% CI for weights based on sample
xbar <- mean(sample_weights, na.rm = TRUE) #sample mean
s <- sd(sample_weights, na.rm = TRUE) #sample sd
zc <- qnorm(0.975) # Corrected to only calculate once for the upper tail
se <- s/sqrt(n) # Changed to use sample standard deviation 's' instead of population 'sigma'
E <- zc*se
lower_bound_CI <- xbar - E
upper_bound_CI <- xbar + E
cat('95% confidence interval for population mean: (',lower_bound_CI,',',upper_bound_CI,')')
#TWO TAILED HYPOTHESIS TEST
#Step 1: HO: mu = mean(weights),  HA: mu != mean(weights)
claim <- "H0"
#Step 2:
alpha <- 0.05
zc <- qnorm(1 - alpha/2) # Corrected to find the critical value for both tails
#Step 3:
xbar <- mean(sample_weights, na.rm = TRUE)
mu_xbar = mu
se <- sigma/sqrt(n)
z = (xbar-mu_xbar)/se
if (!is.na(z)) { # Added check to ensure z is not NA before proceeding
if (z > 0) {
p <- (1- pnorm(z,0,1))*2
} else {
p <- pnorm(z,0,1)*2
}
z
p
#Step 4:
if (p > 0.05){
cat('Since p > 0.05: do not reject H0.')
rejectH0 <- FALSE
} else {
cat('Since p < 0.05: reject H0.')
rejectH0 <- TRUE
}
#Step 5
if (claim == "H0" & rejectH0 == TRUE){
cat('There is enough evidence to reject the claim.')
} else if (claim == "H0" & rejectH0 == FALSE) {
cat('There is not enough evidence to reject the claim.')
} else if (claim == "HA" & rejectH0 == TRUE) {
cat('There is enough evidence to support the claim.')
} else {
cat('There is not enough evidence to support the claim.')
}
}
#Confirm CI and hypothesis test with z.test function
z.test(sample_weights, mu = mu, sigma.x = sigma, conf.level = 0.95)
# Calculate sample mean and standard deviation
xbar <- mean(df$weight, na.rm = TRUE) # Sample mean
s <- sd(df$weight, na.rm = TRUE) # Sample standard deviation
n <- nrow(df) # Sample size
cat('The sample mean penguin weight is:',xbar,'with sample standard deviation',s)
#CONFIDENCE INTERVAL
#Construct 95% CI for weights based on your sample
tc <- qt(0.975,n-1)
se <- s/sqrt(n)
E <- tc*se
lower_bound_CI <- xbar - E
upper_bound_CI <- xbar + E
cat('95% confidence interval for population mean: (',lower_bound_CI,',',upper_bound_CI,')')
# Bootstrap estimation for population mean weight in grams
# 1. Ensure the 'weight' column is numeric, in case it's not
df$weight <- as.numeric(as.character(df$weight))
# 2. Bootstrap Function
bootstrap_mean <- function(df, n_bootstrap) {
bootstrap_means <- numeric(n_bootstrap)
for (i in 1:n_bootstrap) {
sample_indices <- sample(1:length(df), replace = TRUE)
sample_data <- df[sample_indices]
bootstrap_means[i] <- mean(sample_data, na.rm = TRUE)
}
return(bootstrap_means)
}
# 3. Generate Bootstrap Distribution
# Assuming we want to perform 1000 bootstrap resamples
n_bootstrap <- 15000
bootstrap_distribution <- bootstrap_mean(df$weight, n_bootstrap)
# 4. Estimate Mean and Confidence Interval
estimated_mean <- mean(bootstrap_distribution)
conf_interval <- quantile(bootstrap_distribution, probs = c(0.025, 0.975))
# Print the results
print(paste("Estimated Mean:", estimated_mean))
print(paste("95% Confidence Interval:", conf_interval[1], "-", conf_interval[2]))
# TWO TAILED HYPOTHESIS TEST
# Define hypotheses
# Null hypothesis (HO): mu = 4202
# Alternative hypothesis (HA): mu != 4202
# Step 1: Significance level
alpha <- 0.05
# Step 2: Calculate test statistic
mu_0 <- 4202 # Hypothesized population mean
se <- s / sqrt(n) # Standard error
t <- (xbar - mu_0) / se # Test statistic
# Step 3: Calculate p-value for two-tailed test
p <- 2 * (1 - pt(abs(t), n - 1))
cat('Test statistic:', t, '\n')
cat('P-value:', p, '\n')
# Step 4: Decision rule
if (p > alpha) {
cat('Since p > alpha: do not reject H0.\n')
rejectH0 <- FALSE
} else {
cat('Since p <= alpha: reject H0.\n')
rejectH0 <- TRUE
}
# Step 5: Conclusion
if (!rejectH0) {
cat('There is not enough evidence to reject the null hypothesis (HO).\n')
} else {
cat('There is enough evidence to reject the null hypothesis (HO).\n')
}
#Confirm CI and hypothesis test with z.test function
result <- t.test(df$weight, mu = 4202) #for sample data set
#result <- t.test(sample_heights, mu = 78) #for populations data set
result
#z.test(sample_heights, mu = mu, sigma.x = sigma, conf.level = 0.95)
library(car)
library(MASS)
source("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/DATA5100_Statistical-Methods/Final Project - PalmerPenguins/palmerpenguins_final-paper.Rmd")
library(multcomp)
library(tidyverse)
library(multcomp)
library(car)  # for Levene's test
library(MASS) # for Box-Cox transformation
# Remove rows with missing values in the variables of interest
penguins_complete <- na.omit(df[, c("species", "weight")])
# Perform Levene's test for equal variances
leveneTest(weight ~ species, data = penguins_complete)
### Levene's test shows that the variances are definitely
### not equal, so a standard ANOVA test should not be used.
###### Alternative 1: Welch's ANOVA
anova_results <- oneway.test(weight ~ species, data = penguins_complete, var.equal = FALSE)
# Output the results of Welch's ANOVA
anova_results
###### Alternative 2: Box-Cox Transformation
# Apply the Box-Cox transformation
bc <- boxcox(weight ~ species, data = penguins_complete)
# Find the lambda that maximizes the log-likelihood
best_lambda <- bc$x[which.max(bc$y)]
# Transform the data using the best lambda
penguins_complete$weight_transformed <- (penguins_complete$weight^best_lambda - 1) / best_lambda
# Diagnostic plot to assess normality of transformed data
hist(penguins_complete$weight_transformed, main = "Histogram of Transformed Body Mass", xlab = "Transformed Body Mass")
qqnorm(penguins_complete$weight_transformed)
qqline(penguins_complete$body_mass_g_transformed)
library(tidyverse)
library(multcomp)
library(car)  # for Levene's test
library(MASS) # for Box-Cox transformation
# Remove rows with missing values in the variables of interest
penguins_complete <- na.omit(df[, c("species", "weight")])
# Perform Levene's test for equal variances
leveneTest(weight ~ species, data = penguins_complete)
### Levene's test shows that the variances are definitely
### not equal, so a standard ANOVA test should not be used.
###### Alternative 1: Welch's ANOVA
anova_results <- oneway.test(weight ~ species, data = penguins_complete, var.equal = FALSE)
# Output the results of Welch's ANOVA
anova_results
###### Alternative 2: Box-Cox Transformation
# Apply the Box-Cox transformation
bc <- boxcox(weight ~ species, data = penguins_complete)
# Find the lambda that maximizes the log-likelihood
best_lambda <- bc$x[which.max(bc$y)]
# Transform the data using the best lambda
penguins_complete$weight_transformed <- (penguins_complete$weight^best_lambda - 1) / best_lambda
# Diagnostic plot to assess normality of transformed data
hist(penguins_complete$weight_transformed, main = "Histogram of Transformed Body Mass", xlab = "Transformed Body Mass")
qqnorm(penguins_complete$weight_transformed)
qqline(penguins_complete$weight_transformed)
# The plot should be a straight line. It's not.
###### Alternative 3: Log Transformation of weight
# Apply log transformation
penguins_complete$weight_log <- log(penguins_complete$weight)
# We can now proceed with the analysis using the transformed data
# The following example performs a simple linear model (ANOVA) on the transformed data
anova_log <- aov(weight_log ~ species, data = penguins_complete)
# Output the summary of the ANOVA
summary(anova_log)
##### All three alternatives reach the same conclusion:
##### The null hypothesis that the population means are
##### equal should be rejected.
m <- aov(weight ~ species, df)
summary(m)
# Perform Tukey's HSD test
tukey_results <- TukeyHSD(m, conf.level = 0.95)
# Print the results of Tukey's HSD test
print(tukey_results)
source("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/DATA5100_Statistical-Methods/Final Project - PalmerPenguins/palmerpenguins_final-paper.Rmd")
library(binom)
library(tidyverse)
library(dplyr)
library(stats)
# Assuming the proportion of Adelie penguins in the dataset
# is our population proportion
p_population <- mean(df$species == "Adelie")
# Take a random sample of size 100 from the dataset
set.seed(666) # For reproducibility
sample_data <- df[sample(nrow(df), 100), ]
# Calculate the sample proportion of Adelie penguins
p_sample <- mean(sample_data$species == "Adelie")
# Construct a 95% confidence interval for the population proportion
conf_interval <- binom.confint(x = sum(sample_data$species == "Adelie"),
n = 100,
conf.level = 0.95,
methods = "exact")
# Extract lower and upper confidence limits
lower_bound <- conf_interval$lower
upper_bound <- conf_interval$upper
# Conduct a z hypothesis test
z_test <- prop.test(x = sum(sample_data$species == "Adelie"),
n = 100,
p = p_population,
alternative = "two.sided",
conf.level = 0.95)
# Print the results
print(conf_interval)
print(z_test)
cat('The population proportion of Adelie penguins is ',p_population)
cat('The 95% confidence interval for the population proportion of Adelie penguins is (',
lower_bound, ', ', upper_bound, ')', sep = '')
# TWO TAILED HYPOTHESIS TEST
# Step 1: Null and Alternative Hypotheses
# H0: p = 0.44, HA: p != 0.44
population_p <- 0.44
claim <- "H0"
# Step 2: Define alpha level and critical z value
alpha <- 0.05
zc <- qnorm(1 - alpha/2) # critical value for two-tailed test
# Step 3: Calculate sample proportion and z statistic
phat <- mean(df$species == "Adelie") # sample proportion of Adelie penguins
n <- length(df$species) # sample size
se <- sqrt(population_p * (1 - population_p) / n) # standard error
z <- (phat - population_p) / se # z statistic
# Calculate p-value
p_value <- 2 * (1 - pnorm(abs(z))) # two-tailed p-value
# Print z statistic and p-value
cat("Z-statistic:", z, "\nP-value:", p_value)
# Step 4: Decision rule
rejectH0 <- FALSE
if (p_value < alpha) {
cat('Since p < alpha: reject H0.\n')
rejectH0 <- TRUE
} else {
cat('Since p >= alpha: do not reject H0.\n')
}
# Step 5: Conclusion based on the claim
if (claim == "H0" && rejectH0 == TRUE) {
cat('There is enough evidence to reject the claim.\n')
} else if (claim == "H0" && rejectH0 == FALSE) {
cat('There is not enough evidence to reject the claim.\n')
} else if (claim == "HA" && rejectH0 == TRUE) {
cat('There is enough evidence to support the claim.\n')
} else {
cat('There is not enough evidence to support the claim.\n')
}
# Confirm CI with binom.confint
num_adelie <- sum(df$species == "Adelie")
# Asymptotic (Wald) confidence interval
conf_int <- binom.confint(x = num_adelie, n = n, method = "asymptotic", conf.level = 1 - alpha)
# Print the confidence interval
cat('The 95% confidence interval for the population proportion of Adelie penguins is (',
conf_int$lower, ', ', conf_int$upper, ')\n', sep = '')
# One-sample test for the proportion of Adélie penguins
# Testing against the null hypothesis that the proportion is 0.44
num_adelie <- sum(df$species == "Adelie")
n <- length(df$species) # Total number of observations in the sample
# Perform the test
one_prop_test <- prop.test(x = num_adelie, n = n, p = population_p, alternative = "two.sided", conf.level = 0.95)
# Print the results
print(one_prop_test)
library(binom)
library(tidyverse)
library(dplyr)
library(stats)
# Assuming the proportion of Adelie penguins in the dataset
# is our population proportion
p_population <- mean(df$species == "Adelie")
# Take a random sample of size 100 from the dataset
set.seed(666) # For reproducibility
sample_data <- df[sample(nrow(df), 100), ]
# Calculate the sample proportion of Adelie penguins
p_sample <- mean(sample_data$species == "Adelie")
# Construct a 95% confidence interval for the population proportion
conf_interval <- binom.confint(x = sum(sample_data$species == "Adelie"),
n = 100,
conf.level = 0.95,
methods = "exact")
# Extract lower and upper confidence limits
lower_bound <- conf_interval$lower
upper_bound <- conf_interval$upper
# Conduct a z hypothesis test
z_test <- prop.test(x = sum(sample_data$species == "Adelie"),
n = 100,
p = p_population,
alternative = "two.sided",
conf.level = 0.95)
# Print the results
print(conf_interval)
print(z_test)
cat('The population proportion of Adelie penguins is ',p_population)
cat('The 95% confidence interval for the population proportion of Adelie penguins is (',
lower_bound, ', ', upper_bound, ')', sep = '')
# TWO TAILED HYPOTHESIS TEST
# Step 1: Null and Alternative Hypotheses
# H0: p = 0.44, HA: p != 0.44
population_p <- 0.44
claim <- "H0"
# Step 2: Define alpha level and critical z value
alpha <- 0.05
zc <- qnorm(1 - alpha/2) # critical value for two-tailed test
# Step 3: Calculate sample proportion and z statistic
phat <- mean(df$species == "Adelie") # sample proportion of Adelie penguins
n <- length(df$species) # sample size
se <- sqrt(population_p * (1 - population_p) / n) # standard error
z <- (phat - population_p) / se # z statistic
# Calculate p-value
p_value <- 2 * (1 - pnorm(abs(z))) # two-tailed p-value
# Print z statistic and p-value
cat("Z-statistic:", z, "\nP-value:", p_value)
# Step 4: Decision rule
rejectH0 <- FALSE
if (p_value < alpha) {
cat('Since p < alpha: reject H0.\n')
rejectH0 <- TRUE
} else {
cat('Since p >= alpha: do not reject H0.\n')
}
# Step 5: Conclusion based on the claim
if (claim == "H0" && rejectH0 == TRUE) {
cat('There is enough evidence to reject the claim.\n')
} else if (claim == "H0" && rejectH0 == FALSE) {
cat('There is not enough evidence to reject the claim.\n')
} else if (claim == "HA" && rejectH0 == TRUE) {
cat('There is enough evidence to support the claim.\n')
} else {
cat('There is not enough evidence to support the claim.\n')
}
# Confirm CI with binom.confint
num_adelie <- sum(df$species == "Adelie")
# Asymptotic (Wald) confidence interval
conf_int <- binom.confint(x = num_adelie, n = n, method = "asymptotic", conf.level = 1 - alpha)
# Print the confidence interval
cat('The 95% confidence interval for the population proportion of Adelie penguins is (',
conf_int$lower, ', ', conf_int$upper, ')\n', sep = '')
# One-sample test for the proportion of Adélie penguins
# Testing against the null hypothesis that the proportion is 0.44
num_adelie <- sum(df$species == "Adelie")
n <- length(df$species) # Total number of observations in the sample
# Perform the test
one_prop_test <- prop.test(x = num_adelie, n = n, p = population_p, alternative = "two.sided", conf.level = 0.95)
# Print the results
print(one_prop_test)
###### Chi square goodness of fit test
### to test the distribution of species in the penguins dataset
# Set seed for reproducibility
set.seed(666)
# Observe actual frequencies for each species
actual_frequencies <- table(df$species)
# Assuming we expect the species to be evenly distributed
expected_frequencies <- rep(1/length(unique(df$species)), length(unique(df$species)))
# Perform chi-square goodness of fit test
chi_square_test <- chisq.test(x = actual_frequencies, p = expected_frequencies)
# Output the result of the chi-square test
chi_square_test
# Chi-squared test for given probabilities
#
# data:  actual_frequencies
# X-squared = 31.907, df = 2, p-value = 1.179e-07
##### Chi-square test for independence
### between `species` and `island`
# Test the independence between 'species' and 'island' in the penguins dataset
# Create a contingency table of the two categorical variables
contingency_table <- table(df$species, df$island)
# Perform chi-square test of independence
chi_square_independence_test <- chisq.test(contingency_table)
# Output the result of the chi-square test of independence
chi_square_independence_test
# Pearson's Chi-squared test
#
# data:  contingency_table
# X-squared = 299.55, df = 4, p-value < 2.2e-16
source("//wdmycloudex4100/Axel-Ibiza/Andrex_Ibiza/DATA5100_Statistical-Methods/Final Project - PalmerPenguins/palmerpenguins_final-paper.Rmd")
